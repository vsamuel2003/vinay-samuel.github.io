---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a rising senior at Carnegie Mellon University, passionate about Natural Language Processing (NLP) and Artificial Intelligence (AI). As I prepare for graduate studies in these fields, I've been fortunate to work with several distinguished advisors on cutting-edge projects.

Under the guidance of [Prof. Karthik Narasimhan](https://karthikncode.github.io) in the Princeton NLP Group, I led research on developing PersonaGym, the first evaluation framework for persona agents in Large Language Models (LLMs). This project has contributed significantly to our understanding of AI personalities and their interactions.

I also collaborated with [Prof. Cornelia Caragea](https://www.cs.uic.edu/~cornelia/) on ImplicitAVE, the first open-sourced dataset for implicit attribution value extraction. Our work was accepted to ACL Findings 2024, marking a significant advancement in the field of natural language understanding.

Currently, I'm working with [Prof. Daphne Ippolito](https://www.daphnei.com) on LLM output control, exploring ways to enhance the reliability and consistency of AI-generated content.

These diverse experiences have solidified my commitment to pushing the boundaries of NLP and AI, and I'm excited to continue this journey in my graduate studies and beyond.

## News

- **Dec 10, 2023**: Was invited to be an oral session chair in EMNLP 2023 at Singapore.
- **Oct 9, 2023**: Three papers accepted at EMNLP! [Toxicity in ChatGPT](link), [Conditional STS](link), and [MUX-PLMs](link).
- **Oct 1, 2023**: Our workshop titled [PERSONALIZE: Personalization of Generative AI Systems](link) will be co-organized with EACL 2024 in the beautiful and historic Malta.
- **Sep 24, 2023**: Our work [Toxicity in ChatGPT](link) was featured on Wall Street Journal, along with a quote from my conversation with them.
- **Apr 25, 2023**: Our work [SemSup-XC](link) is accepted at ICML 2023. SemSup-XC achieves state-of-the-art results on extreme classification.
- **Apr 12, 2023**: Our work on AI safety which analyzes toxicity in ChatGPT was featured on media outlets like [CNBC](link), [VentureBeat](link), [TechCrunch](link), and [Gizmodo](link). A website summarizing our work can be found [here](link).
- **Apr 12, 2023**: Our work on AI safety titled "Toxicity in ChatGPT: Analyzing Persona-assigned Language Models" is out. Find it [here](link). Work done with my wonderful collaborators at Princeton, AI2, and Georgia Tech.
- **Feb 20, 2023**: Our pre-print titled "MUX-PLMs: Pre-training Language Models with Data Multiplexing" is now available! Find it [here](link).
- **Feb 20, 2023**: Our pre-print titled "SemSup-XC: Semantic Supervision for Zero and Few-shot Extreme Classification" is now available! Find it [here](link).
